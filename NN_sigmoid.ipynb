{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'0': 23364, '1': 6636, 'default payment next month': 1})\n",
      "           X1 X2 X3 X4  X5  X6  X7  X8  X9 X10  ...     X14     X15     X16  \\\n",
      "1       20000  2  2  1  24   2   2  -1  -1  -2  ...     689       0       0   \n",
      "2      120000  2  2  2  26  -1   2   0   0   0  ...    2682    3272    3455   \n",
      "3       90000  2  2  2  34   0   0   0   0   0  ...   13559   14331   14948   \n",
      "4       50000  2  2  1  37   0   0   0   0   0  ...   49291   28314   28959   \n",
      "5       50000  1  2  1  57  -1   0  -1   0   0  ...   35835   20940   19146   \n",
      "6       50000  1  1  2  37   0   0   0   0   0  ...   57608   19394   19619   \n",
      "7      500000  1  1  2  29   0   0   0   0   0  ...  445007  542653  483003   \n",
      "8      100000  2  2  2  23   0  -1  -1   0   0  ...     601     221    -159   \n",
      "9      140000  2  3  1  28   0   0   2   0   0  ...   12108   12211   11793   \n",
      "10      20000  1  3  2  35  -2  -2  -2  -2  -1  ...       0       0   13007   \n",
      "11     200000  2  3  2  34   0   0   2   0   0  ...    5535    2513    1828   \n",
      "12     260000  2  1  2  51  -1  -1  -1  -1  -1  ...    9966    8517   22287   \n",
      "13     630000  2  2  2  41  -1   0  -1  -1  -1  ...    6500    6500    6500   \n",
      "14      70000  1  2  2  30   1   2   2   0   0  ...   65701   66782   36137   \n",
      "15     250000  1  1  2  29   0   0   0   0   0  ...   63561   59696   56875   \n",
      "16      50000  2  3  3  23   1   2   0   0   0  ...   28116   28771   29531   \n",
      "17      20000  1  1  2  24   0   0   2   2   2  ...   17428   18338   17905   \n",
      "18     320000  1  1  1  49   0   0   0  -1  -1  ...  194663   70074    5856   \n",
      "19     360000  2  1  1  49   1  -2  -2  -2  -2  ...       0       0       0   \n",
      "20     180000  2  1  2  29   1  -2  -2  -2  -2  ...       0       0       0   \n",
      "21     130000  2  3  2  39   0   0   0   0   0  ...   24489   20616   11802   \n",
      "22     120000  2  2  1  39  -1  -1  -1  -1  -1  ...     316       0     632   \n",
      "23      70000  2  2  2  26   2   0   0   2   2  ...   45020   44006   46905   \n",
      "24     450000  2  1  1  40  -2  -2  -2  -2  -2  ...    1473     560       0   \n",
      "25      90000  1  1  2  23   0   0   0  -1   0  ...       0    5398    6360   \n",
      "26      50000  1  3  2  23   0   0   0   0   0  ...   36023   28967   29829   \n",
      "27      60000  1  1  2  27   1  -2  -1  -1  -1  ...     259     -57     127   \n",
      "28      50000  2  3  2  30   0   0   0   0   0  ...   17163   17878   18931   \n",
      "29      50000  2  3  1  47  -1  -1  -1  -1  -1  ...    3416    2040   30430   \n",
      "30      50000  1  1  2  26   0   0   0   0   0  ...   17496   17907   18375   \n",
      "...       ... .. .. ..  ..  ..  ..  ..  ..  ..  ...     ...     ...     ...   \n",
      "29971  360000  1  1  1  34  -1  -1  -1   0   0  ...   64069   49005    8676   \n",
      "29972   80000  1  3  1  36   0   0   0   0   0  ...   68279   69674   71070   \n",
      "29973  190000  1  1  1  37   0   0   0   0   0  ...    5869   29223   19616   \n",
      "29974  230000  1  2  1  35   1  -2  -2  -2  -2  ...       0       0       0   \n",
      "29975   50000  1  2  1  37   1   2   2   2   0  ...    4328    2846    1585   \n",
      "29976  220000  1  2  1  41   0   0  -1  -1  -2  ...    1369    5924    1759   \n",
      "29977   40000  1  2  2  47   2   2   3   2   2  ...   53415   51259   47151   \n",
      "29978  420000  1  1  2  34   0   0   0   0   0  ...  140011  141695  144839   \n",
      "29979  310000  1  2  1  39   0   0   0   0   0  ...  233854  219409  216540   \n",
      "29980  180000  1  1  1  32  -2  -2  -2  -2  -2  ...       0       0       0   \n",
      "29981   50000  1  3  2  42   0   0   0   0   0  ...   49397   50360   19971   \n",
      "29982   50000  1  2  1  44   1   2   2   2   0  ...   33101   28192   22676   \n",
      "29983   90000  1  2  1  36   0   0   0   0   0  ...   10306   11328   12036   \n",
      "29984   20000  1  2  1  44  -2  -2  -2  -2  -2  ...    2712    2882    9235   \n",
      "29985   30000  1  2  2  38  -1  -1  -2  -1  -1  ...    2939    1993    1907   \n",
      "29986  240000  1  1  2  30  -2  -2  -2  -2  -2  ...       0       0       0   \n",
      "29987  360000  1  1  2  35  -1  -1  -2  -2  -2  ...       0       0       0   \n",
      "29988  130000  1  1  2  34   0   0   0   0   0  ...   15546  108047   93708   \n",
      "29989  250000  1  1  1  34   0   0   0   0   0  ...  243075  245750  175005   \n",
      "29990  150000  1  1  2  35  -1  -1  -1  -1  -1  ...      -3     780       0   \n",
      "29991  140000  1  2  1  41   0   0   0   0   0  ...  139110  138262   49675   \n",
      "29992  210000  1  2  1  34   3   2   2   2   2  ...    2500    2500    2500   \n",
      "29993   10000  1  3  1  43   0   0   0  -2  -2  ...       0       0       0   \n",
      "29994  100000  1  1  2  38   0  -1  -1   0   0  ...  102996   70626   69473   \n",
      "29995   80000  1  2  2  34   2   2   2   2   2  ...   79384   77519   82607   \n",
      "29996  220000  1  3  1  39   0   0   0   0   0  ...  208365   88004   31237   \n",
      "29997  150000  1  3  2  43  -1  -1  -1  -1   0  ...    3502    8979    5190   \n",
      "29998   30000  1  2  2  37   4   3   2  -1   0  ...    2758   20878   20582   \n",
      "29999   80000  1  3  1  41   1  -1   0   0   0  ...   76304   52774   11855   \n",
      "30000   50000  1  2  1  46   0   0   0   0   0  ...   49764   36535   32428   \n",
      "\n",
      "          X17    X18     X19    X20    X21     X22    X23  \n",
      "1           0      0     689      0      0       0      0  \n",
      "2        3261      0    1000   1000   1000       0   2000  \n",
      "3       15549   1518    1500   1000   1000    1000   5000  \n",
      "4       29547   2000    2019   1200   1100    1069   1000  \n",
      "5       19131   2000   36681  10000   9000     689    679  \n",
      "6       20024   2500    1815    657   1000    1000    800  \n",
      "7      473944  55000   40000  38000  20239   13750  13770  \n",
      "8         567    380     601      0    581    1687   1542  \n",
      "9        3719   3329       0    432   1000    1000   1000  \n",
      "10      13912      0       0      0  13007    1122      0  \n",
      "11       3731   2306      12     50    300    3738     66  \n",
      "12      13668  21818    9966   8583  22301       0   3640  \n",
      "13       2870   1000    6500   6500   6500    2870      0  \n",
      "14      36894   3200       0   3000   3000    1500      0  \n",
      "15      55512   3000    3000   3000   3000    3000   3000  \n",
      "16      30211      0    1500   1100   1200    1300   1100  \n",
      "17      19104   3200       0   1500      0    1650      0  \n",
      "18     195599  10358   10000  75940  20000  195599  50000  \n",
      "19          0      0       0      0      0       0      0  \n",
      "20          0      0       0      0      0       0      0  \n",
      "21        930   3000    1537   1000   2000     930  33764  \n",
      "22        316    316     316      0    632     316      0  \n",
      "23      46012   2007    3582      0   3601       0   1820  \n",
      "24          0  19428    1473    560      0       0   1128  \n",
      "25       8292   5757       0   5398   1200    2045   2000  \n",
      "26      30046   1973    1426   1001   1432    1062    997  \n",
      "27       -189      0    1000      0    500       0   1000  \n",
      "28      19617   1300    1300   1000   1500    1000   1012  \n",
      "29        257   3415    3421   2044  30430     257      0  \n",
      "30      11400   1500    1500   1000   1000    1600      0  \n",
      "...       ...    ...     ...    ...    ...     ...    ...  \n",
      "29971   19487  52951   64535   8907     53   19584  16080  \n",
      "29972   73612   2395    2500   2530   2556    3700   3000  \n",
      "29973  148482   2000    3869  25128  10115  148482   4800  \n",
      "29974       0      0       0      0      0       0      0  \n",
      "29975    1324      0    3000      0      0    1000   1000  \n",
      "29976    1824   8840    6643   5924   1759    1824   7022  \n",
      "29977   46934   4000       0   2000      0    3520      0  \n",
      "29978  147954   7000    7000   5500   5500    5600   5000  \n",
      "29979  210675  10029    9218  10029   8049    8040  10059  \n",
      "29980       0      0       0      0      0       0      0  \n",
      "29981   19694  10000    4000   5000   3000    4500   2000  \n",
      "29982   14647   2300    1700      0    517     503    585  \n",
      "29983   14329   1500    1500   1500   1200    2500      0  \n",
      "29984    1719   2890    2720   2890   9263    1824   1701  \n",
      "29985    3319    923    2977   1999   3057    3319   1000  \n",
      "29986       0      0       0      0      0       0      0  \n",
      "29987       0      0       0      0      0       0      0  \n",
      "29988   97353   3000    2000  93000   4000    5027   4005  \n",
      "29989  179687  65000    8800   9011   6000    7000   6009  \n",
      "29990       0   9054       0    783      0       0      0  \n",
      "29991   46121   6000    7000   4228   1505    2000   2000  \n",
      "29992    2500      0       0      0      0       0      0  \n",
      "29993       0   2000       0      0      0       0      0  \n",
      "29994   55004   2000  111784   4000   3000    2000   2000  \n",
      "29995   81158   7000    3500      0   7000       0   4000  \n",
      "29996   15980   8500   20000   5003   3047    5000   1000  \n",
      "29997       0   1837    3526   8998    129       0      0  \n",
      "29998   19357      0       0  22000   4200    2000   3100  \n",
      "29999   48944  85900    3409   1178   1926   52964   1804  \n",
      "30000   15313   2078    1800   1430   1000    1000   1000  \n",
      "\n",
      "[30000 rows x 23 columns]\n",
      "       Y\n",
      "1      1\n",
      "2      1\n",
      "3      0\n",
      "4      0\n",
      "5      0\n",
      "6      0\n",
      "7      0\n",
      "8      0\n",
      "9      0\n",
      "10     0\n",
      "11     0\n",
      "12     0\n",
      "13     0\n",
      "14     1\n",
      "15     0\n",
      "16     0\n",
      "17     1\n",
      "18     0\n",
      "19     0\n",
      "20     0\n",
      "21     0\n",
      "22     1\n",
      "23     1\n",
      "24     1\n",
      "25     0\n",
      "26     0\n",
      "27     1\n",
      "28     0\n",
      "29     0\n",
      "30     0\n",
      "...   ..\n",
      "29971  0\n",
      "29972  0\n",
      "29973  0\n",
      "29974  1\n",
      "29975  1\n",
      "29976  0\n",
      "29977  1\n",
      "29978  0\n",
      "29979  0\n",
      "29980  0\n",
      "29981  0\n",
      "29982  0\n",
      "29983  1\n",
      "29984  0\n",
      "29985  0\n",
      "29986  0\n",
      "29987  0\n",
      "29988  0\n",
      "29989  0\n",
      "29990  0\n",
      "29991  0\n",
      "29992  1\n",
      "29993  0\n",
      "29994  0\n",
      "29995  1\n",
      "29996  0\n",
      "29997  0\n",
      "29998  1\n",
      "29999  1\n",
      "30000  1\n",
      "\n",
      "[30000 rows x 1 columns]\n",
      "(30000, 23)\n",
      "(30000, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 24000 samples, validate on 6000 samples\n",
      "Epoch 1/100\n",
      "24000/24000 [==============================] - 2s 75us/step - loss: 0.6042 - acc: 0.6810 - val_loss: 0.5245 - val_acc: 0.7838\n",
      "Epoch 2/100\n",
      "24000/24000 [==============================] - 1s 28us/step - loss: 0.5284 - acc: 0.7775 - val_loss: 0.5189 - val_acc: 0.7838\n",
      "Epoch 3/100\n",
      "24000/24000 [==============================] - 1s 32us/step - loss: 0.5258 - acc: 0.7775 - val_loss: 0.5174 - val_acc: 0.7838\n",
      "Epoch 4/100\n",
      "24000/24000 [==============================] - 1s 25us/step - loss: 0.5234 - acc: 0.7775 - val_loss: 0.5147 - val_acc: 0.7838\n",
      "Epoch 5/100\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.5223 - acc: 0.7775 - val_loss: 0.5145 - val_acc: 0.7838\n",
      "Epoch 6/100\n",
      "24000/24000 [==============================] - 1s 31us/step - loss: 0.5210 - acc: 0.7775 - val_loss: 0.5136 - val_acc: 0.7838\n",
      "Epoch 7/100\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.5207 - acc: 0.7775 - val_loss: 0.5130 - val_acc: 0.7838\n",
      "Epoch 8/100\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.5213 - acc: 0.7775 - val_loss: 0.5146 - val_acc: 0.7838\n",
      "Epoch 9/100\n",
      "24000/24000 [==============================] - 1s 33us/step - loss: 0.5208 - acc: 0.7775 - val_loss: 0.5141 - val_acc: 0.7838\n",
      "Epoch 10/100\n",
      "24000/24000 [==============================] - 1s 42us/step - loss: 0.5209 - acc: 0.7775 - val_loss: 0.5138 - val_acc: 0.7838\n",
      "Epoch 11/100\n",
      "24000/24000 [==============================] - 1s 41us/step - loss: 0.5212 - acc: 0.7775 - val_loss: 0.5136 - val_acc: 0.7838\n",
      "Epoch 12/100\n",
      "24000/24000 [==============================] - 1s 41us/step - loss: 0.5209 - acc: 0.7775 - val_loss: 0.5131 - val_acc: 0.7838\n",
      "Epoch 13/100\n",
      "24000/24000 [==============================] - 1s 40us/step - loss: 0.5209 - acc: 0.7775 - val_loss: 0.5145 - val_acc: 0.7838\n",
      "Epoch 14/100\n",
      "24000/24000 [==============================] - 1s 41us/step - loss: 0.5200 - acc: 0.7775 - val_loss: 0.5135 - val_acc: 0.7838\n",
      "Epoch 15/100\n",
      "24000/24000 [==============================] - 1s 45us/step - loss: 0.5196 - acc: 0.7775 - val_loss: 0.5126 - val_acc: 0.7838\n",
      "Epoch 16/100\n",
      "24000/24000 [==============================] - 1s 45us/step - loss: 0.5196 - acc: 0.7775 - val_loss: 0.5132 - val_acc: 0.7838\n",
      "Epoch 17/100\n",
      "24000/24000 [==============================] - 1s 41us/step - loss: 0.5197 - acc: 0.7775 - val_loss: 0.5127 - val_acc: 0.7838\n",
      "Epoch 18/100\n",
      "24000/24000 [==============================] - 1s 43us/step - loss: 0.5196 - acc: 0.7775 - val_loss: 0.5123 - val_acc: 0.7838\n",
      "Epoch 19/100\n",
      "24000/24000 [==============================] - 1s 41us/step - loss: 0.5197 - acc: 0.7775 - val_loss: 0.5130 - val_acc: 0.7838\n",
      "Epoch 20/100\n",
      "24000/24000 [==============================] - 1s 40us/step - loss: 0.5188 - acc: 0.7775 - val_loss: 0.5143 - val_acc: 0.7838\n",
      "Epoch 21/100\n",
      "24000/24000 [==============================] - 1s 41us/step - loss: 0.5204 - acc: 0.7775 - val_loss: 0.5128 - val_acc: 0.7838\n",
      "Epoch 22/100\n",
      "24000/24000 [==============================] - 1s 41us/step - loss: 0.5200 - acc: 0.7775 - val_loss: 0.5126 - val_acc: 0.7838\n",
      "Epoch 23/100\n",
      "24000/24000 [==============================] - 1s 42us/step - loss: 0.5192 - acc: 0.7775 - val_loss: 0.5122 - val_acc: 0.7838\n",
      "Epoch 24/100\n",
      "24000/24000 [==============================] - 1s 43us/step - loss: 0.5200 - acc: 0.7775 - val_loss: 0.5141 - val_acc: 0.7838\n",
      "Epoch 25/100\n",
      "24000/24000 [==============================] - 1s 41us/step - loss: 0.5202 - acc: 0.7775 - val_loss: 0.5130 - val_acc: 0.7838\n",
      "Epoch 26/100\n",
      "24000/24000 [==============================] - 1s 41us/step - loss: 0.5200 - acc: 0.7775 - val_loss: 0.5143 - val_acc: 0.7838\n",
      "Epoch 27/100\n",
      "24000/24000 [==============================] - 1s 41us/step - loss: 0.5197 - acc: 0.7775 - val_loss: 0.5128 - val_acc: 0.7838\n",
      "Epoch 28/100\n",
      "24000/24000 [==============================] - 1s 41us/step - loss: 0.5190 - acc: 0.7775 - val_loss: 0.5133 - val_acc: 0.7838\n",
      "Epoch 29/100\n",
      "24000/24000 [==============================] - 1s 40us/step - loss: 0.5195 - acc: 0.7775 - val_loss: 0.5130 - val_acc: 0.7838\n",
      "Epoch 30/100\n",
      "24000/24000 [==============================] - 1s 40us/step - loss: 0.5191 - acc: 0.7775 - val_loss: 0.5127 - val_acc: 0.7838\n",
      "Epoch 31/100\n",
      "24000/24000 [==============================] - 1s 44us/step - loss: 0.5189 - acc: 0.7775 - val_loss: 0.5125 - val_acc: 0.7838\n",
      "Epoch 32/100\n",
      "24000/24000 [==============================] - 1s 46us/step - loss: 0.5191 - acc: 0.7775 - val_loss: 0.5128 - val_acc: 0.7838\n",
      "Epoch 33/100\n",
      "24000/24000 [==============================] - 1s 39us/step - loss: 0.5191 - acc: 0.7775 - val_loss: 0.5132 - val_acc: 0.7838\n",
      "Epoch 34/100\n",
      "24000/24000 [==============================] - 1s 41us/step - loss: 0.5189 - acc: 0.7775 - val_loss: 0.5129 - val_acc: 0.7838\n",
      "Epoch 35/100\n",
      "24000/24000 [==============================] - 1s 42us/step - loss: 0.5186 - acc: 0.7775 - val_loss: 0.5126 - val_acc: 0.7838\n",
      "Epoch 36/100\n",
      "24000/24000 [==============================] - 1s 39us/step - loss: 0.5183 - acc: 0.7775 - val_loss: 0.5124 - val_acc: 0.7838\n",
      "Epoch 37/100\n",
      "24000/24000 [==============================] - 1s 38us/step - loss: 0.5180 - acc: 0.7775 - val_loss: 0.5119 - val_acc: 0.7838\n",
      "Epoch 38/100\n",
      "24000/24000 [==============================] - 1s 41us/step - loss: 0.5179 - acc: 0.7775 - val_loss: 0.5139 - val_acc: 0.7838\n",
      "Epoch 39/100\n",
      "24000/24000 [==============================] - 1s 37us/step - loss: 0.5186 - acc: 0.7775 - val_loss: 0.5127 - val_acc: 0.7838\n",
      "Epoch 40/100\n",
      "24000/24000 [==============================] - 1s 38us/step - loss: 0.5185 - acc: 0.7775 - val_loss: 0.5121 - val_acc: 0.7838\n",
      "Epoch 41/100\n",
      "24000/24000 [==============================] - 1s 41us/step - loss: 0.5188 - acc: 0.7775 - val_loss: 0.5121 - val_acc: 0.7838\n",
      "Epoch 42/100\n",
      "24000/24000 [==============================] - 1s 39us/step - loss: 0.5187 - acc: 0.7775 - val_loss: 0.5121 - val_acc: 0.7838\n",
      "Epoch 43/100\n",
      "24000/24000 [==============================] - 1s 37us/step - loss: 0.5192 - acc: 0.7775 - val_loss: 0.5132 - val_acc: 0.7838\n",
      "Epoch 44/100\n",
      "24000/24000 [==============================] - 1s 37us/step - loss: 0.5197 - acc: 0.7775 - val_loss: 0.5130 - val_acc: 0.7838\n",
      "Epoch 45/100\n",
      "24000/24000 [==============================] - 1s 36us/step - loss: 0.5194 - acc: 0.7775 - val_loss: 0.5132 - val_acc: 0.7838\n",
      "Epoch 46/100\n",
      "24000/24000 [==============================] - 1s 39us/step - loss: 0.5192 - acc: 0.7775 - val_loss: 0.5139 - val_acc: 0.7838\n",
      "Epoch 47/100\n",
      "24000/24000 [==============================] - 1s 40us/step - loss: 0.5181 - acc: 0.7775 - val_loss: 0.5132 - val_acc: 0.7838\n",
      "Epoch 48/100\n",
      "24000/24000 [==============================] - 1s 45us/step - loss: 0.5178 - acc: 0.7775 - val_loss: 0.5133 - val_acc: 0.7838\n",
      "Epoch 49/100\n",
      "24000/24000 [==============================] - 1s 44us/step - loss: 0.5181 - acc: 0.7775 - val_loss: 0.5121 - val_acc: 0.7838\n",
      "Epoch 50/100\n",
      "24000/24000 [==============================] - 1s 37us/step - loss: 0.5177 - acc: 0.7775 - val_loss: 0.5109 - val_acc: 0.7838\n",
      "Epoch 51/100\n",
      "24000/24000 [==============================] - 1s 40us/step - loss: 0.5162 - acc: 0.7775 - val_loss: 0.5125 - val_acc: 0.7838\n",
      "Epoch 52/100\n",
      "24000/24000 [==============================] - 1s 39us/step - loss: 0.5181 - acc: 0.7775 - val_loss: 0.5120 - val_acc: 0.7838\n",
      "Epoch 53/100\n",
      "24000/24000 [==============================] - 1s 37us/step - loss: 0.5189 - acc: 0.7775 - val_loss: 0.5140 - val_acc: 0.7838\n",
      "Epoch 54/100\n",
      "24000/24000 [==============================] - 1s 41us/step - loss: 0.5196 - acc: 0.7775 - val_loss: 0.5132 - val_acc: 0.7838\n",
      "Epoch 55/100\n",
      "24000/24000 [==============================] - 1s 40us/step - loss: 0.5193 - acc: 0.7775 - val_loss: 0.5130 - val_acc: 0.7838\n",
      "Epoch 56/100\n",
      "24000/24000 [==============================] - 1s 43us/step - loss: 0.5202 - acc: 0.7775 - val_loss: 0.5142 - val_acc: 0.7838\n",
      "Epoch 57/100\n",
      "24000/24000 [==============================] - 1s 38us/step - loss: 0.5206 - acc: 0.7775 - val_loss: 0.5143 - val_acc: 0.7838\n",
      "Epoch 58/100\n",
      "24000/24000 [==============================] - 1s 37us/step - loss: 0.5206 - acc: 0.7775 - val_loss: 0.5144 - val_acc: 0.7838\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24000/24000 [==============================] - 1s 40us/step - loss: 0.5205 - acc: 0.7775 - val_loss: 0.5144 - val_acc: 0.7838\n",
      "Epoch 60/100\n",
      "24000/24000 [==============================] - 1s 43us/step - loss: 0.5200 - acc: 0.7775 - val_loss: 0.5143 - val_acc: 0.7838\n",
      "Epoch 61/100\n",
      "24000/24000 [==============================] - 1s 40us/step - loss: 0.5197 - acc: 0.7775 - val_loss: 0.5140 - val_acc: 0.7838\n",
      "Epoch 62/100\n",
      "24000/24000 [==============================] - 1s 39us/step - loss: 0.5196 - acc: 0.7775 - val_loss: 0.5134 - val_acc: 0.7838\n",
      "Epoch 63/100\n",
      "24000/24000 [==============================] - 1s 41us/step - loss: 0.5194 - acc: 0.7775 - val_loss: 0.5146 - val_acc: 0.7838\n",
      "Epoch 64/100\n",
      "24000/24000 [==============================] - 1s 44us/step - loss: 0.5203 - acc: 0.7775 - val_loss: 0.5145 - val_acc: 0.7838\n",
      "Epoch 65/100\n",
      "24000/24000 [==============================] - 1s 46us/step - loss: 0.5202 - acc: 0.7775 - val_loss: 0.5135 - val_acc: 0.7838\n",
      "Epoch 66/100\n",
      "24000/24000 [==============================] - 1s 41us/step - loss: 0.5200 - acc: 0.7775 - val_loss: 0.5130 - val_acc: 0.7838\n",
      "Epoch 67/100\n",
      "24000/24000 [==============================] - 1s 42us/step - loss: 0.5196 - acc: 0.7775 - val_loss: 0.5124 - val_acc: 0.7838\n",
      "Epoch 68/100\n",
      "24000/24000 [==============================] - 1s 40us/step - loss: 0.5188 - acc: 0.7775 - val_loss: 0.5124 - val_acc: 0.7838\n",
      "Epoch 69/100\n",
      "24000/24000 [==============================] - 1s 41us/step - loss: 0.5195 - acc: 0.7775 - val_loss: 0.5138 - val_acc: 0.7838\n",
      "Epoch 70/100\n",
      "24000/24000 [==============================] - 1s 41us/step - loss: 0.5190 - acc: 0.7776 - val_loss: 0.5121 - val_acc: 0.7838\n",
      "Epoch 71/100\n",
      "24000/24000 [==============================] - 1s 41us/step - loss: 0.5182 - acc: 0.7775 - val_loss: 0.5119 - val_acc: 0.7838\n",
      "Epoch 72/100\n",
      "24000/24000 [==============================] - 1s 41us/step - loss: 0.5190 - acc: 0.7775 - val_loss: 0.5112 - val_acc: 0.7838\n",
      "Epoch 73/100\n",
      "24000/24000 [==============================] - 1s 41us/step - loss: 0.5183 - acc: 0.7775 - val_loss: 0.5111 - val_acc: 0.7838\n",
      "Epoch 74/100\n",
      "24000/24000 [==============================] - 1s 40us/step - loss: 0.5175 - acc: 0.7775 - val_loss: 0.5114 - val_acc: 0.7838\n",
      "Epoch 75/100\n",
      "24000/24000 [==============================] - 1s 40us/step - loss: 0.5191 - acc: 0.7776 - val_loss: 0.5140 - val_acc: 0.7838\n",
      "Epoch 76/100\n",
      "24000/24000 [==============================] - 1s 43us/step - loss: 0.5194 - acc: 0.7775 - val_loss: 0.5160 - val_acc: 0.7838\n",
      "Epoch 77/100\n",
      "24000/24000 [==============================] - 1s 38us/step - loss: 0.5210 - acc: 0.7775 - val_loss: 0.5137 - val_acc: 0.7838\n",
      "Epoch 78/100\n",
      "24000/24000 [==============================] - 1s 39us/step - loss: 0.5209 - acc: 0.7775 - val_loss: 0.5153 - val_acc: 0.7838\n",
      "Epoch 79/100\n",
      "24000/24000 [==============================] - 1s 39us/step - loss: 0.5205 - acc: 0.7775 - val_loss: 0.5135 - val_acc: 0.7838\n",
      "Epoch 80/100\n",
      "24000/24000 [==============================] - 1s 45us/step - loss: 0.5207 - acc: 0.7776 - val_loss: 0.5139 - val_acc: 0.7838\n",
      "Epoch 81/100\n",
      "24000/24000 [==============================] - 1s 45us/step - loss: 0.5207 - acc: 0.7776 - val_loss: 0.5140 - val_acc: 0.7838\n",
      "Epoch 82/100\n",
      "24000/24000 [==============================] - 1s 43us/step - loss: 0.5211 - acc: 0.7776 - val_loss: 0.5137 - val_acc: 0.7838\n",
      "Epoch 83/100\n",
      "24000/24000 [==============================] - 1s 40us/step - loss: 0.5210 - acc: 0.7775 - val_loss: 0.5139 - val_acc: 0.7838\n",
      "Epoch 84/100\n",
      "24000/24000 [==============================] - 1s 42us/step - loss: 0.5203 - acc: 0.7775 - val_loss: 0.5130 - val_acc: 0.7838\n",
      "Epoch 85/100\n",
      "24000/24000 [==============================] - 1s 40us/step - loss: 0.5210 - acc: 0.7775 - val_loss: 0.5137 - val_acc: 0.7838\n",
      "Epoch 86/100\n",
      "24000/24000 [==============================] - 1s 41us/step - loss: 0.5215 - acc: 0.7775 - val_loss: 0.5151 - val_acc: 0.7838\n",
      "Epoch 87/100\n",
      "24000/24000 [==============================] - 1s 41us/step - loss: 0.5214 - acc: 0.7776 - val_loss: 0.5139 - val_acc: 0.7838\n",
      "Epoch 88/100\n",
      "24000/24000 [==============================] - 1s 40us/step - loss: 0.5210 - acc: 0.7775 - val_loss: 0.5140 - val_acc: 0.7838\n",
      "Epoch 89/100\n",
      "24000/24000 [==============================] - 1s 41us/step - loss: 0.5208 - acc: 0.7776 - val_loss: 0.5135 - val_acc: 0.7838\n",
      "Epoch 90/100\n",
      "24000/24000 [==============================] - 1s 42us/step - loss: 0.5208 - acc: 0.7775 - val_loss: 0.5139 - val_acc: 0.7838\n",
      "Epoch 91/100\n",
      "24000/24000 [==============================] - 1s 41us/step - loss: 0.5207 - acc: 0.7775 - val_loss: 0.5137 - val_acc: 0.7838\n",
      "Epoch 92/100\n",
      "24000/24000 [==============================] - 1s 42us/step - loss: 0.5205 - acc: 0.7775 - val_loss: 0.5130 - val_acc: 0.7838\n",
      "Epoch 93/100\n",
      "24000/24000 [==============================] - 1s 39us/step - loss: 0.5205 - acc: 0.7775 - val_loss: 0.5139 - val_acc: 0.7838\n",
      "Epoch 94/100\n",
      "24000/24000 [==============================] - 1s 40us/step - loss: 0.5212 - acc: 0.7775 - val_loss: 0.5137 - val_acc: 0.7838\n",
      "Epoch 95/100\n",
      "24000/24000 [==============================] - 1s 37us/step - loss: 0.5209 - acc: 0.7775 - val_loss: 0.5132 - val_acc: 0.7838\n",
      "Epoch 96/100\n",
      "24000/24000 [==============================] - 1s 41us/step - loss: 0.5212 - acc: 0.7775 - val_loss: 0.5148 - val_acc: 0.7838\n",
      "Epoch 97/100\n",
      "24000/24000 [==============================] - 1s 45us/step - loss: 0.5221 - acc: 0.7776 - val_loss: 0.5151 - val_acc: 0.7838\n",
      "Epoch 98/100\n",
      "24000/24000 [==============================] - 1s 44us/step - loss: 0.5218 - acc: 0.7776 - val_loss: 0.5151 - val_acc: 0.7838\n",
      "Epoch 99/100\n",
      "24000/24000 [==============================] - 1s 38us/step - loss: 0.5217 - acc: 0.7776 - val_loss: 0.5146 - val_acc: 0.7838\n",
      "Epoch 100/100\n",
      "24000/24000 [==============================] - 1s 40us/step - loss: 0.5213 - acc: 0.7775 - val_loss: 0.5145 - val_acc: 0.7838\n",
      "This is eval [0.5145126843452453, 0.7838333333333334]\n",
      "[['0']\n",
      " ['0']\n",
      " ['0']\n",
      " ...\n",
      " ['1']\n",
      " ['0']\n",
      " ['0']] [[0.27711055]\n",
      " [0.27711055]\n",
      " [0.19391418]\n",
      " ...\n",
      " [0.13917524]\n",
      " [0.27711055]\n",
      " [0.13110113]]\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " ...\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_squared_log_error, mean_absolute_error\n",
    "\n",
    "\n",
    "#def Default_accuracy(y_test, y_pred):\n",
    "#    \"\"\"A predicted move is correct if the largest output is 1 in the test vector.\"\"\"\n",
    "#    return np.mean(y_test[y_pred == np.max(y_pred, axis=1, keepdims=True)])\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "df = pd.read_csv (\"CreditCard.csv\")\n",
    "\n",
    "print(Counter(df[\"Y\"]))\n",
    "\n",
    "# For design matrix select only columns 0-18, without 18 and include last two columns:\n",
    "\n",
    "Xdes = df.iloc[1:,list(range(1,24))]\n",
    "\n",
    "print(Xdes)\n",
    "\n",
    "Default = df.iloc[1:, 24:25]\n",
    "\n",
    "print(Default)\n",
    "\n",
    "print(Xdes.shape)\n",
    "print(Default.shape)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(Xdes, Default, test_size=0.2)\n",
    "\n",
    "# First number is No. of neurons, next is activation function, and number of inputs\n",
    "# Each line is a new layer, first one is input, two hidden and one output\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(32, activation=\"sigmoid\", input_dim=Xdes.shape[1]))\n",
    "\n",
    "# Avoid overfitting, randomly switch off 30% neurons with dropout layers:\n",
    "\n",
    "#model.add(tf.keras.layers.Dropout(0.3))\n",
    "model.add(tf.keras.layers.Dense(16, activation=\"sigmoid\"))\n",
    "#model.add(tf.keras.layers.Dropout(0.3))\n",
    "model.add(tf.keras.layers.Dense(8, activation=\"sigmoid\"))\n",
    "model.add(tf.keras.layers.Dense(Default.shape[1], activation=\"sigmoid\"))\n",
    "          \n",
    "# Define the cost/loss function, this loss function is good for multiple options          \n",
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Train your model\n",
    "          \n",
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=100,\n",
    "    batch_size=128,\n",
    "    validation_data=[X_test, y_test])\n",
    "\n",
    "model.save(\"credit.h5\")\n",
    "\n",
    "eval_result = model.evaluate(X_test,y_test, verbose=0)\n",
    "print('This is eval', eval_result)\n",
    "\n",
    "print(y_test.values, model.predict(X_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score: -0.27578141611737217\n",
      "MSE: 0.21616666666666667\n",
      "Mean Squared Log Error 0.10385792650865121\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
